





import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.metrics import roc_auc_score, classification_report
from catboost import CatBoostClassifier
import optuna


apparel_purchases = pd.read_csv('/Users/valardoh/Documents/ЯНДЕКС_ПРАКТИКУМ_DS/Мастерская_2/filtered_data/apparel-purchases.csv')
apparel_messages = pd.read_csv('/Users/valardoh/Documents/ЯНДЕКС_ПРАКТИКУМ_DS/Мастерская_2/filtered_data/apparel-messages.csv')
apparel_target_binary = pd.read_csv('/Users/valardoh/Documents/ЯНДЕКС_ПРАКТИКУМ_DS/Мастерская_2/filtered_data/apparel-target_binary.csv')


display(apparel_purchases)
display(apparel_messages)
display(apparel_target_binary)








apparel_purchases


apparel_purchases.info()


print("=== Пропуски ===")
print(apparel_purchases.isna().sum())
print("\n=== Дубликаты ===")
print("Общее количество дубликатов:", apparel_purchases.duplicated().sum())


apparel_purchases[apparel_purchases.duplicated()].head(50)


apparel_purchases.price.unique()


apparel_purchases['price'] = apparel_purchases['price'].astype('int64')
apparel_purchases['date'] = pd.to_datetime(apparel_purchases['date'], format='%Y-%m-%d')


apparel_purchases[apparel_purchases['price'] >= 10000]


apparel_purchases = apparel_purchases.drop(apparel_purchases[apparel_purchases['price'] >= 10000].index)


fig, ax = plt.subplots(figsize=(10, 5))

sns.histplot(data=apparel_purchases['price'], bins=50, kde=True, ax=ax)

ax.set_xlabel('Цена покупки', fontsize=12)
ax.set_ylabel('Количество покупок', fontsize=12)
ax.set_title('Распределение цен на товары', fontsize=14)

ax.grid(True, linestyle='--', alpha=0.7)

plt.tight_layout()
plt.show()


apparel_purchases[apparel_purchases['quantity'] >= 5]


purchases_target = pd.merge(
    apparel_purchases,
    apparel_target_binary,
    on = 'client_id',
    how = 'left',
)

purchases_target


numeric_cols = purchases_target.select_dtypes(include=['int64', 'float64']).columns.tolist()

if 'target' in purchases_target.columns and 'target' not in numeric_cols:
    numeric_cols.append('target')

corr_matrix = purchases_target[numeric_cols].corr()

plt.figure(figsize=(10, 8))
sns.heatmap(
    corr_matrix,
    annot=True,
    fmt=".2f",
    cmap='coolwarm',
    center=0,
    linewidths=0.5,
    vmin=-1,
    vmax=1
)

plt.title('Матрица корреляции', pad=20)
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()











apparel_messages


apparel_messages.info()


print("=== Пропуски ===")
print(apparel_messages.isna().sum())
print("\n=== Дубликаты ===")
print("Общее количество дубликатов:", apparel_messages.duplicated().sum())


apparel_messages[apparel_messages.duplicated()].head(50)


apparel_messages = apparel_messages.drop_duplicates()


apparel_messages['date'] = pd.to_datetime(apparel_messages['date'], format='%Y-%m-%d')
apparel_messages['created_at'] = pd.to_datetime(apparel_messages['created_at'], format='%Y-%m-%d %H:%M:%S')


plt.figure(figsize=(10, 6))
ax = sns.countplot(
    data=apparel_messages, 
    x='channel', 
    hue='channel',
    palette='viridis',
    legend=False
)

for p in ax.patches:
    ax.annotate(
        f'{int(p.get_height())}', 
        (p.get_x() + p.get_width() / 2., p.get_height()), 
        ha='center', 
        va='center', 
        xytext=(0, 5), 
        textcoords='offset points'
    )

plt.title('Канал рассылки')
plt.ylabel('Количество')
plt.tight_layout()
plt.show()


plt.figure(figsize=(10, 6))
ax = sns.countplot(
    data=apparel_messages, 
    x='event', 
    hue='event',
    palette='viridis', 
    legend=False
)

plt.xticks(rotation=90)

for p in ax.patches:
    ax.annotate(
        f'{int(p.get_height())}', 
        (p.get_x() + p.get_width() / 2., p.get_height()), 
        ha='center', 
        va='center', 
        xytext=(0, 5), 
        textcoords='offset points'
    )

plt.title('Действие с сообщением')
plt.tight_layout()
plt.show()


messages_target = pd.merge(
    apparel_messages,
    apparel_target_binary,
    on = 'client_id',
    how = 'left',
)

messages_target['target'] = messages_target['target'].astype('Int64')

messages_target


messages_target.isna().sum()


numeric_cols = messages_target.select_dtypes(include=['int64', 'float64']).columns.tolist()

if 'target' in messages_target.columns and 'target' not in numeric_cols:
    numeric_cols.append('target')

corr_matrix = messages_target[numeric_cols].corr()

plt.figure(figsize=(10, 8))
sns.heatmap(
    corr_matrix,
    annot=True,
    fmt=".2f",
    cmap='coolwarm',
    center=0,
    linewidths=0.5,
    vmin=-1,
    vmax=1
)

plt.title('Матрица корреляции', pad=20)
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()











display(purchases_target)
display(messages_target)


agg_dfs = pd.merge(
    purchases_target,
    messages_target,
    on = ['client_id', 'message_id'],
    how='inner',
    suffixes=('_purchases', '_messages')
)


agg_dfs


agg_dfs.target_messages.value_counts()


discrepancies = agg_dfs[agg_dfs['target_purchases'] != agg_dfs['target_messages']]
print(f"Количество строк с расхождениями: {len(discrepancies)}")


agg_dfs = agg_dfs.drop('target_purchases', axis=1).rename(columns={'target_messages':'target'})


agg_dfs


agg_dfs.info()


print("=== Пропуски ===")
print(agg_dfs.isna().sum())
print("\n=== Дубликаты ===")
print("Общее количество дубликатов:", agg_dfs.duplicated().sum())


agg_dfs[agg_dfs.duplicated()]


agg_dfs = agg_dfs.drop_duplicates()


fig, ax = plt.subplots(figsize=(10, 5))

sns.histplot(data=agg_dfs['price'], bins=50, kde=True, ax=ax)

ax.set_xlabel('Цена покупки', fontsize=12)
ax.set_ylabel('Количество покупок', fontsize=12)
ax.set_title('Распределение цен на товары', fontsize=14)

ax.grid(True, linestyle='--', alpha=0.7)

plt.tight_layout()
plt.show()


plt.figure(figsize=(10, 6))
ax = sns.countplot(
    data=agg_dfs, 
    x='channel', 
    hue='channel',
    palette='viridis',
    legend=False
)

for p in ax.patches:
    ax.annotate(
        f'{int(p.get_height())}', 
        (p.get_x() + p.get_width() / 2., p.get_height()), 
        ha='center', 
        va='center', 
        xytext=(0, 5), 
        textcoords='offset points'
    )

plt.title('Канал рассылки')
plt.ylabel('Количество')
plt.tight_layout()
plt.show()


plt.figure(figsize=(10, 6))
ax = sns.countplot(
    data=agg_dfs, 
    x='event', 
    hue='event',
    palette='viridis', 
    legend=False
)

plt.xticks(rotation=90)

for p in ax.patches:
    ax.annotate(
        f'{int(p.get_height())}', 
        (p.get_x() + p.get_width() / 2., p.get_height()), 
        ha='center', 
        va='center', 
        xytext=(0, 5), 
        textcoords='offset points'
    )

plt.title('Действие с сообщением')
plt.tight_layout()
plt.show()


numeric_cols = agg_dfs.select_dtypes(include=['int64', 'float64']).columns.tolist()

if 'target' in agg_dfs.columns and 'target' not in numeric_cols:
    numeric_cols.append('target')

corr_matrix = agg_dfs[numeric_cols].corr()

plt.figure(figsize=(10, 8))
sns.heatmap(
    corr_matrix,
    annot=True,
    fmt=".2f",
    cmap='coolwarm',
    center=0,
    linewidths=0.5,
    vmin=-1,
    vmax=1
)

plt.title('Матрица корреляции', pad=20)
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()











# Проверка на распродажу
agg_dfs['is_sale'] = agg_dfs['category_ids'].apply(lambda x: 1 if 'sale' in str(x).lower() else 0)

# Разница между покупкой и сообщением
agg_dfs['days_s_message'] = (agg_dfs['date_purchases'] - agg_dfs['date_messages']).dt.days

# Частота покупок по клиенту
purchase_fr = agg_dfs.groupby('client_id')['date_purchases'].count().reset_index()
purchase_fr.columns = ['client_id', 'purchase_frequency']
agg_dfs = agg_dfs.merge(purchase_fr, on='client_id', how='left')

# event признаки
agg_dfs['event_opened'] = (agg_dfs['event'] == 'opened').astype(int)
agg_dfs['event_clicked'] = (agg_dfs['event'] == 'clicked').astype(int)
agg_dfs['event_purchase'] = (agg_dfs['event'] == 'purchase').astype(int)
agg_dfs['event_send'] = (agg_dfs['event'] == 'send').astype(int)
agg_dfs['event_complain'] = (agg_dfs['event'] == 'complain').astype(int)
agg_dfs['event_unsubscribe'] = (agg_dfs['event'] == 'unsubscribe').astype(int)
agg_dfs['event_subscribe'] = (agg_dfs['event'] == 'subscribe').astype(int)
agg_dfs['event_hard_bounce'] = (agg_dfs['event'] == 'hard_bounce').astype(int) 




agg_dfs











display(agg_dfs.head(2))
display(agg_dfs.columns)


numeric_features = ['quantity', 'price', 'is_sale', 
                    'days_s_message', 'purchase_frequency', 'event_opened', 
                    'event_clicked', 'event_purchase', 'event_send', 
                    'event_complain', 'event_unsubscribe', 'event_subscribe', 'event_hard_bounce']
categorical_features = ['channel']

X = agg_dfs[numeric_features + categorical_features]
y = agg_dfs['target']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ]
)

X_train_processed = preprocessor.fit_transform(X_train)
X_test_processed = preprocessor.transform(X_test)








model = CatBoostClassifier(
    iterations=600,
    learning_rate=0.1,
    depth=6,
    eval_metric='AUC',
    random_state=42,
    verbose=100
)

model.fit(X_train_processed, y_train, eval_set=(X_test_processed, y_test))


def cbc_opt(tr):
    params = {
        'iterations': tr.suggest_int('iterations', 100, 1000),
        'depth': tr.suggest_int('depth', 3, 10),
        'learning_rate': tr.suggest_float('learning_rate', 0.01, 0.3),
        'l2_leaf_reg': tr.suggest_float('l2_leaf_reg', 1, 10),
    }
    
    model = CatBoostClassifier(**params, eval_metric='AUC', random_state=42, verbose=False)
    model.fit(X_train_processed, y_train, eval_set=(X_test_processed, y_test))
    return model.get_best_score()['validation']['AUC']


study = optuna.create_study(direction='maximize')
study.optimize(cbc_opt, n_trials=30)


# best_params = study.best_params
# best_params
print('Лучшие параметры:', study.best_params)
print('Лучшая метрика AUC:', study.best_value)


ohe_features = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)
all_feature_names = numeric_features + list(ohe_features)
feature_importance = model.get_feature_importance()

plt.figure(figsize=(10, 8))
plt.barh(all_feature_names, feature_importance)
plt.title('Важность признаков')
plt.tight_layout()
plt.show()


y_pred_proba = model.predict_proba(X_test_processed)[:, 1]
roc_auc = roc_auc_score(y_test, y_pred_proba)

print(f"ROC-AUC: {roc_auc:.4f}")
print(classification_report(y_test, model.predict(X_test_processed)))









